{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOFGAdkMWL593fIaxkvaqz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daveveed/Machine-Learning/blob/main/ANN_Regression_with_callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vupqBX-OyFrG"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, matplotlib as mpl\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "EYuA1IoDyZj6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ],
      "metadata": {
        "id": "QjIEOibhyrnr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective is to predict the price of house using 8 different variables"
      ],
      "metadata": {
        "id": "F01mmO7czFIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing = fetch_california_housing()"
      ],
      "metadata": {
        "id": "qSA-9Qbjy5qc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the independent variables\n",
        "housing.feature_names"
      ],
      "metadata": {
        "id": "mIEp53w9zVfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c131ce4-4b2a-42c9-ff1e-36b6bc9d65b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MedInc',\n",
              " 'HouseAge',\n",
              " 'AveRooms',\n",
              " 'AveBedrms',\n",
              " 'Population',\n",
              " 'AveOccup',\n",
              " 'Latitude',\n",
              " 'Longitude']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting"
      ],
      "metadata": {
        "id": "olL4wJm8OqjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import  train_test_split\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=1)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=1)"
      ],
      "metadata": {
        "id": "NWZhAVeiNGXF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "standadizng"
      ],
      "metadata": {
        "id": "WInOu5SOOt0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "WBBqKvbJOe0I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sudyCYSQFBG",
        "outputId": "d3d076ea-43d5-4a7f-c04e-96c22c1eba3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "metadata": {
        "id": "SYPqx-3pR93t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will be using functional API not sequential "
      ],
      "metadata": {
        "id": "AlEFY4mZPQ4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras import activations\n",
        "# building the model structure\n",
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input_, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs = [input_], outputs = [output])"
      ],
      "metadata": {
        "id": "k7a_deJOPKC_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Td3Po1kVQxiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e430721f-29d6-42c4-cbbd-373088e988cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 30)           270         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.training import optimizer\n",
        "# compile the model\n",
        "model.compile(loss = 'mean_squared_error', \n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3), \n",
        "              metrics=['mae'])"
      ],
      "metadata": {
        "id": "KP2LFL59YRs2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liT-kY8VY9RU",
        "outputId": "73f2f5cb-d889-4a3a-e525-01317a542d53"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4337 - mae: 0.4733 - val_loss: 0.4264 - val_mae: 0.4723\n",
            "Epoch 2/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4319 - mae: 0.4724 - val_loss: 0.4215 - val_mae: 0.4704\n",
            "Epoch 3/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4296 - mae: 0.4710 - val_loss: 0.4164 - val_mae: 0.4706\n",
            "Epoch 4/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4277 - mae: 0.4709 - val_loss: 0.4135 - val_mae: 0.4638\n",
            "Epoch 5/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4265 - mae: 0.4687 - val_loss: 0.4120 - val_mae: 0.4658\n",
            "Epoch 6/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4253 - mae: 0.4682 - val_loss: 0.4138 - val_mae: 0.4652\n",
            "Epoch 7/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4230 - mae: 0.4675 - val_loss: 0.4105 - val_mae: 0.4634\n",
            "Epoch 8/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4209 - mae: 0.4660 - val_loss: 0.4088 - val_mae: 0.4616\n",
            "Epoch 9/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4202 - mae: 0.4653 - val_loss: 0.4123 - val_mae: 0.4609\n",
            "Epoch 10/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4181 - mae: 0.4640 - val_loss: 0.4053 - val_mae: 0.4613\n",
            "Epoch 11/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4170 - mae: 0.4636 - val_loss: 0.4043 - val_mae: 0.4606\n",
            "Epoch 12/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4151 - mae: 0.4622 - val_loss: 0.4054 - val_mae: 0.4609\n",
            "Epoch 13/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4139 - mae: 0.4618 - val_loss: 0.4021 - val_mae: 0.4604\n",
            "Epoch 14/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4126 - mae: 0.4604 - val_loss: 0.3992 - val_mae: 0.4583\n",
            "Epoch 15/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4111 - mae: 0.4597 - val_loss: 0.3982 - val_mae: 0.4557\n",
            "Epoch 16/30\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4098 - mae: 0.4582 - val_loss: 0.3993 - val_mae: 0.4604\n",
            "Epoch 17/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4085 - mae: 0.4582 - val_loss: 0.3975 - val_mae: 0.4544\n",
            "Epoch 18/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4067 - mae: 0.4569 - val_loss: 0.3962 - val_mae: 0.4528\n",
            "Epoch 19/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4058 - mae: 0.4564 - val_loss: 0.3949 - val_mae: 0.4506\n",
            "Epoch 20/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4044 - mae: 0.4553 - val_loss: 0.3940 - val_mae: 0.4518\n",
            "Epoch 21/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4035 - mae: 0.4546 - val_loss: 0.3921 - val_mae: 0.4500\n",
            "Epoch 22/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4015 - mae: 0.4534 - val_loss: 0.3904 - val_mae: 0.4506\n",
            "Epoch 23/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4006 - mae: 0.4527 - val_loss: 0.3889 - val_mae: 0.4485\n",
            "Epoch 24/30\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3994 - mae: 0.4522 - val_loss: 0.3890 - val_mae: 0.4493\n",
            "Epoch 25/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3982 - mae: 0.4512 - val_loss: 0.3870 - val_mae: 0.4465\n",
            "Epoch 26/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3972 - mae: 0.4505 - val_loss: 0.3846 - val_mae: 0.4465\n",
            "Epoch 27/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3959 - mae: 0.4497 - val_loss: 0.3851 - val_mae: 0.4456\n",
            "Epoch 28/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3950 - mae: 0.4495 - val_loss: 0.3840 - val_mae: 0.4445\n",
            "Epoch 29/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3939 - mae: 0.4480 - val_loss: 0.3845 - val_mae: 0.4467\n",
            "Epoch 30/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3924 - mae: 0.4476 - val_loss: 0.3820 - val_mae: 0.4448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HABKmP7FZ5TS",
        "outputId": "68cca9ba-b82a-4e23-b4d4-1aab6dd4e150"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4129 - mae: 0.4531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA5HzVqlaFqd",
        "outputId": "722a76b3-64fc-456f-e4a0-34659af9d6fb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.43369171023368835,\n",
              "  0.431871235370636,\n",
              "  0.4296186566352844,\n",
              "  0.42774248123168945,\n",
              "  0.42651858925819397,\n",
              "  0.4252835512161255,\n",
              "  0.4229722321033478,\n",
              "  0.42088326811790466,\n",
              "  0.42019587755203247,\n",
              "  0.41812628507614136,\n",
              "  0.4170253276824951,\n",
              "  0.41505667567253113,\n",
              "  0.4139396846294403,\n",
              "  0.4125841557979584,\n",
              "  0.4111444056034088,\n",
              "  0.409821093082428,\n",
              "  0.4084743857383728,\n",
              "  0.4066609740257263,\n",
              "  0.4057827889919281,\n",
              "  0.4044336974620819,\n",
              "  0.40345826745033264,\n",
              "  0.40154996514320374,\n",
              "  0.4005703032016754,\n",
              "  0.3993947505950928,\n",
              "  0.3982318043708801,\n",
              "  0.3971969485282898,\n",
              "  0.3959026038646698,\n",
              "  0.39497870206832886,\n",
              "  0.3938557803630829,\n",
              "  0.39243388175964355],\n",
              " 'mae': [0.4733007848262787,\n",
              "  0.47237351536750793,\n",
              "  0.4710439443588257,\n",
              "  0.4709198772907257,\n",
              "  0.4687364995479584,\n",
              "  0.46824562549591064,\n",
              "  0.4674753248691559,\n",
              "  0.4659675657749176,\n",
              "  0.4653179347515106,\n",
              "  0.4639836549758911,\n",
              "  0.463559091091156,\n",
              "  0.46219831705093384,\n",
              "  0.4617635905742645,\n",
              "  0.46043089032173157,\n",
              "  0.4597444236278534,\n",
              "  0.45824509859085083,\n",
              "  0.45822691917419434,\n",
              "  0.45687589049339294,\n",
              "  0.45640885829925537,\n",
              "  0.45526567101478577,\n",
              "  0.45463210344314575,\n",
              "  0.4534386098384857,\n",
              "  0.45271167159080505,\n",
              "  0.4521685540676117,\n",
              "  0.45121675729751587,\n",
              "  0.4505346417427063,\n",
              "  0.4497376084327698,\n",
              "  0.44948720932006836,\n",
              "  0.44800901412963867,\n",
              "  0.44761165976524353],\n",
              " 'val_loss': [0.4264127314090729,\n",
              "  0.42151132225990295,\n",
              "  0.4164007306098938,\n",
              "  0.4134702980518341,\n",
              "  0.41200122237205505,\n",
              "  0.4137532413005829,\n",
              "  0.41054967045783997,\n",
              "  0.4088369905948639,\n",
              "  0.4123433828353882,\n",
              "  0.40527597069740295,\n",
              "  0.40427619218826294,\n",
              "  0.40541601181030273,\n",
              "  0.4021073281764984,\n",
              "  0.3991694152355194,\n",
              "  0.3982267677783966,\n",
              "  0.399265855550766,\n",
              "  0.39751121401786804,\n",
              "  0.3962371349334717,\n",
              "  0.3948827087879181,\n",
              "  0.3940420150756836,\n",
              "  0.3920799493789673,\n",
              "  0.39040443301200867,\n",
              "  0.3888615667819977,\n",
              "  0.38895511627197266,\n",
              "  0.3869953751564026,\n",
              "  0.38456079363822937,\n",
              "  0.385147362947464,\n",
              "  0.3840041160583496,\n",
              "  0.3844676613807678,\n",
              "  0.38203126192092896],\n",
              " 'val_mae': [0.4723356068134308,\n",
              "  0.4704085886478424,\n",
              "  0.4706374704837799,\n",
              "  0.46378573775291443,\n",
              "  0.46577149629592896,\n",
              "  0.46523377299308777,\n",
              "  0.46341851353645325,\n",
              "  0.4616391658782959,\n",
              "  0.4608800411224365,\n",
              "  0.4613476097583771,\n",
              "  0.46059948205947876,\n",
              "  0.46090567111968994,\n",
              "  0.4603743553161621,\n",
              "  0.4582553803920746,\n",
              "  0.45571643114089966,\n",
              "  0.460405170917511,\n",
              "  0.4544205367565155,\n",
              "  0.4527820348739624,\n",
              "  0.4506128132343292,\n",
              "  0.45179975032806396,\n",
              "  0.4500236511230469,\n",
              "  0.45055556297302246,\n",
              "  0.44848886132240295,\n",
              "  0.4493083953857422,\n",
              "  0.4465184509754181,\n",
              "  0.4464603364467621,\n",
              "  0.4455711841583252,\n",
              "  0.44447386264801025,\n",
              "  0.44668176770210266,\n",
              "  0.44476255774497986]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(model_history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "KBVMK6nOaK6m",
        "outputId": "98d97496-2ac4-459a-b24e-cdeb745586f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## saving the model"
      ],
      "metadata": {
        "id": "Pu3FwFIlbICg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.h5') # the .h5 is the extension format to save the model as"
      ],
      "metadata": {
        "id": "ClSrRM-dag4I"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r0QO8VNnbODO",
        "outputId": "f12b8760-268a-4c07-aff8-c3ce3a811135"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the model\n",
        "del model"
      ],
      "metadata": {
        "id": "nb4QQVBkbPvf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clear the session\n",
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "YsBmBd8Vbacb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "R4FaiKg4bjAI",
        "outputId": "2d177d5a-5ddd-447a-c838-a1a89188e2b5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1f8a688cae5d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reload the model\n",
        "model = keras.models.load_model('my_model.h5')"
      ],
      "metadata": {
        "id": "LAF5kN5DblGe"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajk_JH1Eb2Af",
        "outputId": "b1c1c557-722a-41c3-8d18-d9557e87165b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fb3a3753f70>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV9-efnSb3Kz",
        "outputId": "3da8bce9-a951-4093-eed9-89124fcc2944"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 30)           270         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## using call backs during training\n",
        "\n",
        "with this we can save our training at a particular epoch "
      ],
      "metadata": {
        "id": "iuCHVTEmcHi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "VS6rYb6nb6hl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new model to illustrate\n",
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "C1QuqP_UcU-x"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "JFYlPaYRceah"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKCXnHCxc5qS",
        "outputId": "faab9f47-5d6a-405e-950e-44d722f0daa5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('Model-{epoch:02d}.h5')"
      ],
      "metadata": {
        "id": "aie2In98dUn9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tni-M9fpeEsz",
        "outputId": "314a0aee-0edf-436f-969e-2013b1558a5c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 1.0267 - val_loss: 0.7294\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 2.7845 - val_loss: 0.6195\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4726 - val_loss: 0.4304\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4147 - val_loss: 0.3945\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3937 - val_loss: 0.3892\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3814 - val_loss: 0.3681\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3704 - val_loss: 0.3578\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3523\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3577 - val_loss: 0.3479\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3514 - val_loss: 0.3457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del the model\n",
        "del model\n",
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "FUwvQzJNebn1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can load any of the epochs\n",
        "model = keras.models.load_model('Model-10.h5') #this is loading the 10th epoch"
      ],
      "metadata": {
        "id": "5QgU7PFNeu5r"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPoyvDGWe9l0",
        "outputId": "5332a89d-175f-4bdc-b04c-65f00b5d025f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 7ms/step - loss: 0.3756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## choosing the best model\n",
        "\n",
        "- there's no need to save the model at each epoch\n",
        "- we will set the save best to true while creating the check point\n",
        "- it only saves the best one\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aTX0s7QZfF_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "gM5cY4MlfDU9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZZX10vCgLOk",
        "outputId": "7efb0c37-0c74-41d0-cb81-958a8f6f9efb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('Best_MOdel.h5', save_best_only=True)"
      ],
      "metadata": {
        "id": "eJjjo4NUgcgi"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 10,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks = [checkpoint_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TTfWUrvgr4i",
        "outputId": "902175c1-5f9a-47c2-ebf7-0ac45ba5ec8f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 4s 8ms/step - loss: 1.1430 - val_loss: 1.5045\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.6949 - val_loss: 0.4568\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4416 - val_loss: 0.4269\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4154 - val_loss: 0.3943\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3948 - val_loss: 0.3857\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3806 - val_loss: 0.3655\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.3606\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3631 - val_loss: 0.3508\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3578 - val_loss: 0.3451\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3511 - val_loss: 0.3435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('Best_MOdel.h5')\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFFg8KMPhC77",
        "outputId": "22e47cd1-7f13-4b13-f23e-e13b7609352a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 4ms/step - loss: 0.3663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### early stopping callback\n",
        "\n",
        "when we have large epoch and the validation accuracy, and select the nest model."
      ],
      "metadata": {
        "id": "ACLc953ahpwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "oZ4NPZ_Ghd4J"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "dd333gfbmWqg"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation= 'relu', input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "qFR3RrB1mdEs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse', optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
      ],
      "metadata": {
        "id": "ymzLEC0Entng"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('early_stop_model.h5', save_best_only=True)"
      ],
      "metadata": {
        "id": "UtmHMoPYoAwG"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience =10,\n",
        "                                                  restore_best_weights= True) \n",
        "#patience is the no of epochs with no improvement after which training will be stopped"
      ],
      "metadata": {
        "id": "JhRP2KQ-op-0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 200,\n",
        "                    validation_data =(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXE7aJqIqVO3",
        "outputId": "2cc1b1ac-ae5a-4b4a-963f-eeb6b81a9c95"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 2.0136 - val_loss: 0.7592\n",
            "Epoch 2/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6773 - val_loss: 0.5795\n",
            "Epoch 3/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5960 - val_loss: 0.5426\n",
            "Epoch 4/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5667 - val_loss: 0.5176\n",
            "Epoch 5/200\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.5459 - val_loss: 0.5020\n",
            "Epoch 6/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5297 - val_loss: 0.4900\n",
            "Epoch 7/200\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.5166 - val_loss: 0.4806\n",
            "Epoch 8/200\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.5059 - val_loss: 0.4719\n",
            "Epoch 9/200\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.4979 - val_loss: 0.4653\n",
            "Epoch 10/200\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.4903 - val_loss: 0.4599\n",
            "Epoch 11/200\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4839 - val_loss: 0.4544\n",
            "Epoch 12/200\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4782 - val_loss: 0.4504\n",
            "Epoch 13/200\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4730 - val_loss: 0.4463\n",
            "Epoch 14/200\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4683 - val_loss: 0.4422\n",
            "Epoch 15/200\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.4640 - val_loss: 0.4381\n",
            "Epoch 16/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4598 - val_loss: 0.4372\n",
            "Epoch 17/200\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4561 - val_loss: 0.4323\n",
            "Epoch 18/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4525 - val_loss: 0.4287\n",
            "Epoch 19/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4495 - val_loss: 0.4255\n",
            "Epoch 20/200\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4466 - val_loss: 0.4237\n",
            "Epoch 21/200\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4440 - val_loss: 0.4211\n",
            "Epoch 22/200\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4410 - val_loss: 0.4199\n",
            "Epoch 23/200\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4388 - val_loss: 0.4170\n",
            "Epoch 24/200\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4364 - val_loss: 0.4164\n",
            "Epoch 25/200\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4344 - val_loss: 0.4133\n",
            "Epoch 26/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4321 - val_loss: 0.4110\n",
            "Epoch 27/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4301 - val_loss: 0.4101\n",
            "Epoch 28/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4283 - val_loss: 0.4083\n",
            "Epoch 29/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4264 - val_loss: 0.4073\n",
            "Epoch 30/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4245 - val_loss: 0.4054\n",
            "Epoch 31/200\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4226 - val_loss: 0.4041\n",
            "Epoch 32/200\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.4211 - val_loss: 0.4019\n",
            "Epoch 33/200\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4192 - val_loss: 0.4006\n",
            "Epoch 34/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4176 - val_loss: 0.4002\n",
            "Epoch 35/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4160 - val_loss: 0.3989\n",
            "Epoch 36/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4145 - val_loss: 0.3975\n",
            "Epoch 37/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4131 - val_loss: 0.3952\n",
            "Epoch 38/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.3939\n",
            "Epoch 39/200\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4105 - val_loss: 0.3919\n",
            "Epoch 40/200\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 0.4089 - val_loss: 0.3916\n",
            "Epoch 41/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4077 - val_loss: 0.3920\n",
            "Epoch 42/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4063 - val_loss: 0.3883\n",
            "Epoch 43/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4051 - val_loss: 0.3873\n",
            "Epoch 44/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.3878\n",
            "Epoch 45/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4024 - val_loss: 0.3848\n",
            "Epoch 46/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.3854\n",
            "Epoch 47/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.3823\n",
            "Epoch 48/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.3822\n",
            "Epoch 49/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3973 - val_loss: 0.3799\n",
            "Epoch 50/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3960 - val_loss: 0.3805\n",
            "Epoch 51/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3948 - val_loss: 0.3793\n",
            "Epoch 52/200\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.3936 - val_loss: 0.3778\n",
            "Epoch 53/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3924 - val_loss: 0.3769\n",
            "Epoch 54/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3911 - val_loss: 0.3764\n",
            "Epoch 55/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3904 - val_loss: 0.3743\n",
            "Epoch 56/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.3743\n",
            "Epoch 57/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3880 - val_loss: 0.3731\n",
            "Epoch 58/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3870 - val_loss: 0.3718\n",
            "Epoch 59/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3862 - val_loss: 0.3722\n",
            "Epoch 60/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3848 - val_loss: 0.3719\n",
            "Epoch 61/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3841 - val_loss: 0.3696\n",
            "Epoch 62/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3830 - val_loss: 0.3683\n",
            "Epoch 63/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3821 - val_loss: 0.3690\n",
            "Epoch 64/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.3670\n",
            "Epoch 65/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3803 - val_loss: 0.3666\n",
            "Epoch 66/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3794 - val_loss: 0.3661\n",
            "Epoch 67/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3780 - val_loss: 0.3645\n",
            "Epoch 68/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.3644\n",
            "Epoch 69/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.3640\n",
            "Epoch 70/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3758 - val_loss: 0.3641\n",
            "Epoch 71/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.3623\n",
            "Epoch 72/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3742 - val_loss: 0.3622\n",
            "Epoch 73/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.3616\n",
            "Epoch 74/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.3616\n",
            "Epoch 75/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.3594\n",
            "Epoch 76/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.3593\n",
            "Epoch 77/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3703 - val_loss: 0.3585\n",
            "Epoch 78/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3587\n",
            "Epoch 79/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.3575\n",
            "Epoch 80/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.3572\n",
            "Epoch 81/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3673 - val_loss: 0.3557\n",
            "Epoch 82/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.3569\n",
            "Epoch 83/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3659 - val_loss: 0.3540\n",
            "Epoch 84/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3650 - val_loss: 0.3536\n",
            "Epoch 85/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3643 - val_loss: 0.3538\n",
            "Epoch 86/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.3531\n",
            "Epoch 87/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.3533\n",
            "Epoch 88/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.3517\n",
            "Epoch 89/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3613 - val_loss: 0.3533\n",
            "Epoch 90/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.3533\n",
            "Epoch 91/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.3508\n",
            "Epoch 92/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 0.3500\n",
            "Epoch 93/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3585 - val_loss: 0.3482\n",
            "Epoch 94/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3481\n",
            "Epoch 95/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.3473\n",
            "Epoch 96/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3568 - val_loss: 0.3468\n",
            "Epoch 97/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3559 - val_loss: 0.3472\n",
            "Epoch 98/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3455\n",
            "Epoch 99/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3549 - val_loss: 0.3451\n",
            "Epoch 100/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3541 - val_loss: 0.3457\n",
            "Epoch 101/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.3444\n",
            "Epoch 102/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.3451\n",
            "Epoch 103/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.3437\n",
            "Epoch 104/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.3471\n",
            "Epoch 105/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3430\n",
            "Epoch 106/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.3420\n",
            "Epoch 107/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.3459\n",
            "Epoch 108/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3489 - val_loss: 0.3415\n",
            "Epoch 109/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3494 - val_loss: 0.3415\n",
            "Epoch 110/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3396\n",
            "Epoch 111/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3473 - val_loss: 0.3390\n",
            "Epoch 112/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3467 - val_loss: 0.3393\n",
            "Epoch 113/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.3387\n",
            "Epoch 114/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3398\n",
            "Epoch 115/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.3371\n",
            "Epoch 116/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.3377\n",
            "Epoch 117/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3440 - val_loss: 0.3381\n",
            "Epoch 118/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3435 - val_loss: 0.3360\n",
            "Epoch 119/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3382\n",
            "Epoch 120/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3429 - val_loss: 0.3365\n",
            "Epoch 121/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3360\n",
            "Epoch 122/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3416 - val_loss: 0.3361\n",
            "Epoch 123/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3412 - val_loss: 0.3341\n",
            "Epoch 124/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3405 - val_loss: 0.3352\n",
            "Epoch 125/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3408 - val_loss: 0.3349\n",
            "Epoch 126/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3342\n",
            "Epoch 127/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3390 - val_loss: 0.3348\n",
            "Epoch 128/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3392 - val_loss: 0.3341\n",
            "Epoch 129/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3384 - val_loss: 0.3327\n",
            "Epoch 130/200\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.3376 - val_loss: 0.3342\n",
            "Epoch 131/200\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3382 - val_loss: 0.3349\n",
            "Epoch 132/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3373 - val_loss: 0.3334\n",
            "Epoch 133/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3366 - val_loss: 0.3317\n",
            "Epoch 134/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3362 - val_loss: 0.3314\n",
            "Epoch 135/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3358 - val_loss: 0.3320\n",
            "Epoch 136/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.3346\n",
            "Epoch 137/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3351 - val_loss: 0.3310\n",
            "Epoch 138/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3297\n",
            "Epoch 139/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3298\n",
            "Epoch 140/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3339 - val_loss: 0.3308\n",
            "Epoch 141/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3336 - val_loss: 0.3299\n",
            "Epoch 142/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3289\n",
            "Epoch 143/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3328 - val_loss: 0.3285\n",
            "Epoch 144/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3275\n",
            "Epoch 145/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3319 - val_loss: 0.3307\n",
            "Epoch 146/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3281\n",
            "Epoch 147/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3315 - val_loss: 0.3301\n",
            "Epoch 148/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3276\n",
            "Epoch 149/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3306 - val_loss: 0.3270\n",
            "Epoch 150/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3271\n",
            "Epoch 151/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.3279\n",
            "Epoch 152/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3295 - val_loss: 0.3272\n",
            "Epoch 153/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3290 - val_loss: 0.3259\n",
            "Epoch 154/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3290 - val_loss: 0.3268\n",
            "Epoch 155/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3284 - val_loss: 0.3257\n",
            "Epoch 156/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3285 - val_loss: 0.3259\n",
            "Epoch 157/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3282 - val_loss: 0.3241\n",
            "Epoch 158/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3275 - val_loss: 0.3258\n",
            "Epoch 159/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3274 - val_loss: 0.3254\n",
            "Epoch 160/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3274 - val_loss: 0.3253\n",
            "Epoch 161/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3266 - val_loss: 0.3257\n",
            "Epoch 162/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3265 - val_loss: 0.3240\n",
            "Epoch 163/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3248\n",
            "Epoch 164/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3258 - val_loss: 0.3238\n",
            "Epoch 165/200\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3258 - val_loss: 0.3231\n",
            "Epoch 166/200\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3255 - val_loss: 0.3238\n",
            "Epoch 167/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3250 - val_loss: 0.3237\n",
            "Epoch 168/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3244 - val_loss: 0.3242\n",
            "Epoch 169/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3246 - val_loss: 0.3231\n",
            "Epoch 170/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3241 - val_loss: 0.3213\n",
            "Epoch 171/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3240 - val_loss: 0.3227\n",
            "Epoch 172/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3238 - val_loss: 0.3208\n",
            "Epoch 173/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3239 - val_loss: 0.3228\n",
            "Epoch 174/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3206\n",
            "Epoch 175/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3233 - val_loss: 0.3212\n",
            "Epoch 176/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3225 - val_loss: 0.3222\n",
            "Epoch 177/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3219 - val_loss: 0.3224\n",
            "Epoch 178/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3220 - val_loss: 0.3206\n",
            "Epoch 179/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3218 - val_loss: 0.3231\n",
            "Epoch 180/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3214 - val_loss: 0.3202\n",
            "Epoch 181/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3213 - val_loss: 0.3208\n",
            "Epoch 182/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3209 - val_loss: 0.3221\n",
            "Epoch 183/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3206 - val_loss: 0.3201\n",
            "Epoch 184/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3204 - val_loss: 0.3197\n",
            "Epoch 185/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3201 - val_loss: 0.3211\n",
            "Epoch 186/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3199 - val_loss: 0.3192\n",
            "Epoch 187/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3196 - val_loss: 0.3199\n",
            "Epoch 188/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3194 - val_loss: 0.3175\n",
            "Epoch 189/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3201 - val_loss: 0.3199\n",
            "Epoch 190/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3191 - val_loss: 0.3181\n",
            "Epoch 191/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3187 - val_loss: 0.3194\n",
            "Epoch 192/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3179 - val_loss: 0.3169\n",
            "Epoch 193/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3183\n",
            "Epoch 194/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3174 - val_loss: 0.3169\n",
            "Epoch 195/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3169 - val_loss: 0.3181\n",
            "Epoch 196/200\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3169 - val_loss: 0.3176\n",
            "Epoch 197/200\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3163 - val_loss: 0.3178\n",
            "Epoch 198/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3164 - val_loss: 0.3194\n",
            "Epoch 199/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3161 - val_loss: 0.3170\n",
            "Epoch 200/200\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3169 - val_loss: 0.3163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('early_stop_model.h5')\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg8VzYVwrJgb",
        "outputId": "89e1c22b-9164-4ddd-c346-9406b0ddf23e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 3ms/step - loss: 0.3405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "Un_lcIsAsDmT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}