{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3ce9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cc593ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#splitting the data to training and test sets \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cea07d",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e860a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28,1)\n",
    "input_shape = (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f50710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# convert the vector class to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#converting the data type to 'float32' ensures that the data is in \n",
    "#the correct format for numerical computations and enhances compatibility \n",
    "#with machine learning libraries and models.\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#normalisation\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501e096",
   "metadata": {},
   "source": [
    "## creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37cc1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# epochs = 15\n",
    "\n",
    "model = Sequential()\n",
    "# building the convolutional part\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "# add a pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25)) # this will reduce a quater of the nuerons inturn reducing overfitting\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "#connect the layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5)) #droping 50% of the nuerons\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c545a86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               2359552   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 2,405,078\n",
      "Trainable params: 2,405,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49ddc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c167a58",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9f55159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 126s 2ms/step - loss: 0.0617 - accuracy: 0.9824 - val_loss: 0.0415 - val_accuracy: 0.9863\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 120s 2ms/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.0302 - val_accuracy: 0.9907\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: 0.0290 - val_accuracy: 0.9907\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.0292 - val_accuracy: 0.9911\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0353 - val_accuracy: 0.9894\n",
      "The model has successfully traned\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train,\n",
    "                 y_train,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=5,\n",
    "                 verbose=1,\n",
    "                 validation_data=(x_test,y_test))\n",
    "\n",
    "print('The model has successfully traned')\n",
    "\n",
    "model.save('mnist.h5')\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e4eec",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3066232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA:  - 5s 484us/step\n",
      "Test loss: 0.035277919900242705\n",
      "Test accuracy: 0.9894000291824341\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89d031df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(hist.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "152d62de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18668\\2091167414.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# import tensorflow\n",
    "# from tensorflow.keras import backend\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "del model\n",
    "backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59780f23",
   "metadata": {},
   "source": [
    "## creating GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be4f938f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to open file (unable to open file: name = '�HDF\r\n\u001a\n', errno = 22, error message = 'Invalid argument', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18668\\1451709209.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# model = keras.models.load_model('mnist.h5', compile=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geopython\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geopython\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geopython\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 533\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geopython\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to open file (unable to open file: name = '�HDF\r\n\u001a\n', errno = 22, error message = 'Invalid argument', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'mnist.h5'\n",
    "with open(model_path, 'rb') as f:\n",
    "    model_bytes = f.read()\n",
    "model = keras.models.load_model(model_bytes, compile=False)\n",
    "\n",
    "# model = keras.models.load_model('mnist.h5', compile=False)\n",
    "\n",
    "# Create a blank canvas for drawing\n",
    "canvas_width = 280\n",
    "canvas_height = 280\n",
    "\n",
    "# Function to preprocess the drawn image before feeding it into the model\n",
    "def preprocess_image():\n",
    "    # Convert the drawn image to grayscale\n",
    "    image = Image.new('L', (canvas_width, canvas_height))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle([(0, 0), (canvas_width, canvas_height)], fill='black')\n",
    "    draw.line(canvas.coords, fill='white', width=20)\n",
    "    # Resize the image to match the input size of your model\n",
    "    image = image.resize((28, 28))\n",
    "    # Convert the image to a numpy array\n",
    "    image_array = np.array(image)\n",
    "    # Normalize the pixel values\n",
    "    image_array = image_array / 255.0\n",
    "    # Reshape the image array to match the input shape of your model\n",
    "    image_array = np.reshape(image_array, (1, 28, 28, 1))\n",
    "    return image_array\n",
    "\n",
    "# Function to classify the drawn image using the trained model\n",
    "def classify_image():\n",
    "    # Preprocess the drawn image\n",
    "    image_array = preprocess_image()\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(image_array)\n",
    "    # Get the predicted class\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    # Display the predicted class in the GUI\n",
    "    result_label.config(text=f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "# Create the Tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Image Classifier\")\n",
    "\n",
    "# Create a canvas for drawing\n",
    "canvas = tk.Canvas(window, width=canvas_width, height=canvas_height, bg='black')\n",
    "canvas.pack()\n",
    "\n",
    "# Bind mouse events to the canvas\n",
    "canvas.bind(\"<B1-Motion>\", lambda event: canvas.draw(event.x, event.y))\n",
    "\n",
    "# Create a button to classify the drawn image\n",
    "classify_button = tk.Button(window, text=\"Classify\", command=classify_image)\n",
    "classify_button.pack(pady=20)\n",
    "\n",
    "# Create a label to display the predicted class\n",
    "result_label = tk.Label(window, text=\"Predicted Class: \")\n",
    "result_label.pack()\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2c65fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\Documents\\\\Machine learning\\\\note books'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "795737ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to open file (unable to open file: name = '�HDF\r\n\u001a\n', errno = 22, error message = 'Invalid argument', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18668\\1713868100.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geopython\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geopython\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geopython\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 533\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geopython\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to open file (unable to open file: name = '�HDF\r\n\u001a\n', errno = 22, error message = 'Invalid argument', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "\n",
    "model_path = 'model.h5'\n",
    "with open(model_path, 'rb') as f:\n",
    "    model_bytes = f.read()\n",
    "model = keras.models.load_model(model_bytes, compile=False)\n",
    "\n",
    "\n",
    "def predict_digit(img):\n",
    "    #resize image to 28x28 pixels\n",
    "    img = img.resize((28,28))\n",
    "    #convert rgb to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    #reshaping to support our model input and normalizing\n",
    "    img = img.reshape(1,28,28,1)\n",
    "    img = img/255.0\n",
    "    #predicting the class\n",
    "    res = model.predict([img])[0]\n",
    "    return np.argmax(res), max(res)\n",
    "\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "\n",
    "        self.x = self.y = 0\n",
    "\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "\n",
    "        digit, acc = predict_digit(im)\n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "\n",
    "app = App()\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d09dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
